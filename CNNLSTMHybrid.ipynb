{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "526dfd3a-979f-4420-942a-ce31672eac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "N_CLASSES set to 21\n",
      "Data prepared with 37 common features.\n",
      "Scaling and padding data...\n",
      "Padding from 37 to 49 for (7, 7) image.\n",
      "\n",
      "--- Preparing Data for Hybrid Stage 1 ---\n",
      "\n",
      "--- Training Hybrid CNN-LSTM Stage 1 (Detection) ---\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 10, 5, 5, 32)     320       \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 10, 2, 2, 32)     0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 10, 128)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                35800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,721\n",
      "Trainable params: 38,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 9s 35ms/step - loss: 0.5088 - accuracy: 0.6684 - val_loss: 0.6699 - val_accuracy: 0.4647\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.4122 - accuracy: 0.6832 - val_loss: 0.7233 - val_accuracy: 0.4990\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.3983 - accuracy: 0.6991 - val_loss: 0.9734 - val_accuracy: 0.4176\n",
      "Epoch 4/20\n",
      "182/183 [============================>.] - ETA: 0s - loss: 0.3675 - accuracy: 0.7332Restoring model weights from the end of the best epoch: 1.\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.3677 - accuracy: 0.7332 - val_loss: 0.9385 - val_accuracy: 0.4500\n",
      "Epoch 4: early stopping\n",
      "\n",
      "--- Hybrid CNN-LSTM Stage 1 Evaluation ---\n",
      "1586/1586 [==============================] - 12s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.97      0.20      2810\n",
      "           1       1.00      0.55      0.71     47940\n",
      "\n",
      "    accuracy                           0.58     50750\n",
      "   macro avg       0.56      0.76      0.46     50750\n",
      "weighted avg       0.95      0.58      0.68     50750\n",
      "\n",
      "\n",
      "--- Preparing Data for Hybrid Stage 2 ---\n",
      "\n",
      "--- Training Hybrid CNN-LSTM Stage 2 (Classification) ---\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_3 (TimeDis  (None, 10, 5, 5, 32)     320       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 10, 2, 2, 32)     0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, 10, 128)          0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                35800     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 21)                1071      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 39,741\n",
      "Trainable params: 39,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 9s 36ms/step - loss: 2.2121 - accuracy: 0.2898 - val_loss: 1.9693 - val_accuracy: 0.2733\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 6s 35ms/step - loss: 1.5002 - accuracy: 0.4956 - val_loss: 1.8231 - val_accuracy: 0.3447\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.2693 - accuracy: 0.5657 - val_loss: 1.6023 - val_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 6s 32ms/step - loss: 1.1540 - accuracy: 0.6038 - val_loss: 1.4934 - val_accuracy: 0.4639\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 1.0721 - accuracy: 0.6307 - val_loss: 1.5500 - val_accuracy: 0.4635\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.9889 - accuracy: 0.6590 - val_loss: 1.4136 - val_accuracy: 0.4886\n",
      "Epoch 7/20\n",
      "183/183 [==============================] - 6s 33ms/step - loss: 0.9352 - accuracy: 0.6789 - val_loss: 1.4259 - val_accuracy: 0.4867\n",
      "Epoch 8/20\n",
      "183/183 [==============================] - 7s 36ms/step - loss: 0.8774 - accuracy: 0.7020 - val_loss: 1.3101 - val_accuracy: 0.5106\n",
      "Epoch 9/20\n",
      "183/183 [==============================] - 6s 34ms/step - loss: 0.7946 - accuracy: 0.7302 - val_loss: 1.6024 - val_accuracy: 0.4516\n",
      "Epoch 10/20\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.7458 - accuracy: 0.7409 - val_loss: 1.4467 - val_accuracy: 0.4909\n",
      "Epoch 11/20\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.7444 - accuracy: 0.7406Restoring model weights from the end of the best epoch: 8.\n",
      "183/183 [==============================] - 6s 31ms/step - loss: 0.7438 - accuracy: 0.7409 - val_loss: 1.5234 - val_accuracy: 0.5245\n",
      "Epoch 11: early stopping\n",
      "\n",
      "--- Hybrid CNN-LSTM Stage 2 Evaluation ---\n",
      "1586/1586 [==============================] - 13s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.58      0.25      2810\n",
      "           1       0.94      0.83      0.88      2820\n",
      "           2       0.99      0.83      0.90      2820\n",
      "           4       0.64      0.75      0.69      2820\n",
      "           5       0.52      0.11      0.19      2820\n",
      "           6       0.98      0.44      0.60      2820\n",
      "           7       0.58      0.85      0.69      2820\n",
      "           8       0.82      0.37      0.51      2820\n",
      "          10       0.39      0.19      0.25      2820\n",
      "          11       0.70      0.76      0.73      2820\n",
      "          12       0.54      0.46      0.50      2820\n",
      "          13       0.90      0.54      0.68      2820\n",
      "          14       0.98      0.83      0.90      2820\n",
      "          16       0.33      0.00      0.00      2820\n",
      "          17       0.87      0.70      0.78      2820\n",
      "          18       0.55      0.53      0.54      2820\n",
      "          19       0.22      0.05      0.08      2820\n",
      "          20       0.23      0.68      0.35      2820\n",
      "\n",
      "    accuracy                           0.53     50750\n",
      "   macro avg       0.63      0.53      0.53     50750\n",
      "weighted avg       0.63      0.53      0.53     50750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv2D, Flatten, MaxPooling2D, Dropout, LSTM, TimeDistributed\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def create_lstm_dataset(X, y, time_steps=10):\n",
    "    \"\"\"Converts data into sequences for LSTM\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "    \n",
    "def pad_features(X, target_features):\n",
    "    \"\"\"Pads feature vector X to have target_features columns\"\"\"\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    pad_width = target_features - num_features\n",
    "    if pad_width < 0:\n",
    "        return X[:, :target_features]\n",
    "    padding = np.zeros((num_samples, pad_width))\n",
    "    return np.concatenate([X, padding], axis=1)\n",
    "\n",
    "# --- 1. DATA PREPARATION (Load all data) ---\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "# --- Prep for Stage 1 (Binary) ---\n",
    "train_data['binary_fault'] = train_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "test_data['binary_fault'] = test_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "y_train_s1 = train_data['binary_fault'].astype(int)\n",
    "y_test_s1 = test_data['binary_fault'].astype(int)\n",
    "\n",
    "# --- Prep for Stage 2 (Multiclass) ---\n",
    "y_train_s2_labels = train_data['faultNumber'].astype(int)\n",
    "y_test_s2_labels = test_data['faultNumber'].astype(int)\n",
    "\n",
    "all_labels = pd.concat([y_train_s2_labels, y_test_s2_labels])\n",
    "N_CLASSES = int(all_labels.max()) + 1\n",
    "print(f\"N_CLASSES set to {N_CLASSES}\")\n",
    "\n",
    "y_train_s2_cat = to_categorical(y_train_s2_labels, num_classes=N_CLASSES)\n",
    "y_test_s2_cat = to_categorical(y_test_s2_labels, num_classes=N_CLASSES)\n",
    "\n",
    "# --- Prep Features (X) ---\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample', 'binary_fault']\n",
    "X_train = train_data.drop(columns=drop_cols, errors='ignore')\n",
    "X_test = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "common_cols = sorted(list(set(X_train.columns).intersection(set(X_test.columns))))\n",
    "X_train = X_train[common_cols]\n",
    "X_test  = X_test[common_cols]\n",
    "\n",
    "print(f\"Data prepared with {len(common_cols)} common features.\")\n",
    "\n",
    "# --- 2. SCALING & PADDING (Shared) ---\n",
    "print(\"Scaling and padding data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "N_FEATURES = X_train_scaled.shape[1] # 37\n",
    "\n",
    "# Pad features for 7x7 image\n",
    "TARGET_DIM = int(np.ceil(np.sqrt(N_FEATURES)))\n",
    "IMG_ROWS, IMG_COLS = TARGET_DIM, TARGET_DIM\n",
    "TARGET_FEATURES = TARGET_DIM * TARGET_DIM\n",
    "print(f\"Padding from {N_FEATURES} to {TARGET_FEATURES} for ({IMG_ROWS}, {IMG_COLS}) image.\")\n",
    "\n",
    "X_train_padded = pad_features(X_train_scaled, TARGET_FEATURES)\n",
    "X_test_padded = pad_features(X_test_scaled, TARGET_FEATURES)\n",
    "\n",
    "# --- Define Model Parameters ---\n",
    "TIME_STEPS = 10\n",
    "HYBRID_INPUT_SHAPE = (TIME_STEPS, IMG_ROWS, IMG_COLS, 1)\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss', patience=3, verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "#  STAGE 1: HYBRID CNN-LSTM (BINARY)\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n--- Preparing Data for Hybrid Stage 1 ---\")\n",
    "# Create sequences from the PADDED data\n",
    "X_train_s1_seq, y_train_s1_seq = create_lstm_dataset(X_train_padded, y_train_s1.values, TIME_STEPS)\n",
    "X_test_s1_seq, y_test_s1_seq = create_lstm_dataset(X_test_padded, y_test_s1.values, TIME_STEPS)\n",
    "\n",
    "# Reshape data to (Samples, TimeSteps, Rows, Cols, Channels)\n",
    "X_train_s1_hybrid = X_train_s1_seq.reshape((-1, TIME_STEPS, IMG_ROWS, IMG_COLS, 1))\n",
    "X_test_s1_hybrid = X_test_s1_seq.reshape((-1, TIME_STEPS, IMG_ROWS, IMG_COLS, 1))\n",
    "\n",
    "# Calculate class weights for Stage 1\n",
    "weights_s1 = class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train_s1_seq), y=y_train_s1_seq\n",
    ")\n",
    "class_weights_dict_s1 = dict(zip(np.unique(y_train_s1_seq), weights_s1))\n",
    "\n",
    "def build_cnn_lstm_stage1(input_shape):\n",
    "    model = Sequential()\n",
    "    # 1. CNN Feature Extractor (wrapped in TimeDistributed)\n",
    "    model.add(TimeDistributed(\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    # 2. LSTM Sequence Learner\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    \n",
    "    # 3. Classifier Head\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"\\n--- Training Hybrid CNN-LSTM Stage 1 (Detection) ---\")\n",
    "model_s1_hybrid = build_cnn_lstm_stage1(HYBRID_INPUT_SHAPE)\n",
    "model_s1_hybrid.summary()\n",
    "\n",
    "model_s1_hybrid.fit(X_train_s1_hybrid, y_train_s1_seq,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    class_weight=class_weights_dict_s1,\n",
    "                    callbacks=[early_stopper])\n",
    "\n",
    "print(\"\\n--- Hybrid CNN-LSTM Stage 1 Evaluation ---\")\n",
    "y_pred_s1_hybrid = (model_s1_hybrid.predict(X_test_s1_hybrid) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_s1_seq, y_pred_s1_hybrid, zero_division=0))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "#  STAGE 2: HYBRID CNN-LSTM (MULTICLASS)\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n--- Preparing Data for Hybrid Stage 2 ---\")\n",
    "# Create sequences from PADDED data and CATEGORICAL labels\n",
    "X_train_s2_seq, y_train_s2_seq_cat = create_lstm_dataset(X_train_padded, y_train_s2_cat, TIME_STEPS)\n",
    "X_test_s2_seq, y_test_s2_seq_cat = create_lstm_dataset(X_test_padded, y_test_s2_cat, TIME_STEPS)\n",
    "\n",
    "# Reshape X data\n",
    "X_train_s2_hybrid = X_train_s2_seq.reshape((-1, TIME_STEPS, IMG_ROWS, IMG_COLS, 1))\n",
    "X_test_s2_hybrid = X_test_s2_seq.reshape((-1, TIME_STEPS, IMG_ROWS, IMG_COLS, 1))\n",
    "\n",
    "# Create y labels for evaluation\n",
    "_, y_test_s2_seq_labels = create_lstm_dataset(X_test_padded, y_test_s2_labels.values, TIME_STEPS)\n",
    "\n",
    "# Calculate class weights for Stage 2\n",
    "_, y_train_s2_seq_labels = create_lstm_dataset(X_train_padded, y_train_s2_labels.values, TIME_STEPS)\n",
    "unique_labels_s2_seq = np.unique(y_train_s2_seq_labels)\n",
    "weights_s2 = class_weight.compute_class_weight(\n",
    "    'balanced', classes=unique_labels_s2_seq, y=y_train_s2_seq_labels\n",
    ")\n",
    "class_weights_dict_s2 = {i: 1.0 for i in range(N_CLASSES)}\n",
    "calculated_dict_s2 = dict(zip(unique_labels_s2_seq, weights_s2))\n",
    "class_weights_dict_s2.update(calculated_dict_s2)\n",
    "\n",
    "def build_cnn_lstm_stage2(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    # 1. CNN Feature Extractor\n",
    "    model.add(TimeDistributed(\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    # 2. LSTM Sequence Learner\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    \n",
    "    # 3. Classifier Head\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"\\n--- Training Hybrid CNN-LSTM Stage 2 (Classification) ---\")\n",
    "model_s2_hybrid = build_cnn_lstm_stage2(HYBRID_INPUT_SHAPE, N_CLASSES)\n",
    "model_s2_hybrid.summary()\n",
    "\n",
    "model_s2_hybrid.fit(X_train_s2_hybrid, y_train_s2_seq_cat,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    class_weight=class_weights_dict_s2,\n",
    "                    callbacks=[early_stopper])\n",
    "\n",
    "print(\"\\n--- Hybrid CNN-LSTM Stage 2 Evaluation ---\")\n",
    "y_pred_s2_hybrid_probs = model_s2_hybrid.predict(X_test_s2_hybrid)\n",
    "y_pred_s2_hybrid_labels = np.argmax(y_pred_s2_hybrid_probs, axis=1)\n",
    "\n",
    "print(classification_report(y_test_s2_seq_labels, y_pred_s2_hybrid_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b02aafce-1398-4b58-8255-3e6b0cc2adc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "N_CLASSES set to 21\n",
      "Data prepared with 37 common features.\n",
      "Scaling data...\n",
      "\n",
      "--- Preparing Data for 1D-CNN-LSTM Stage 1 ---\n",
      "\n",
      "--- Training Hybrid 1D-CNN-LSTM Stage 1 (Detection) ---\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1 (Conv1D)           (None, 8, 64)             7168      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                23000     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32,769\n",
      "Trainable params: 32,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 7s 20ms/step - loss: 0.4766 - accuracy: 0.6842 - val_loss: 0.6216 - val_accuracy: 0.6550\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.3103 - accuracy: 0.8047 - val_loss: 0.5524 - val_accuracy: 0.7028\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2498 - accuracy: 0.8516 - val_loss: 0.5070 - val_accuracy: 0.7565\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.2310 - accuracy: 0.8649 - val_loss: 0.5191 - val_accuracy: 0.7387\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 3s 16ms/step - loss: 0.2133 - accuracy: 0.8765 - val_loss: 0.5786 - val_accuracy: 0.7387\n",
      "Epoch 6/20\n",
      "180/183 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.8831Restoring model weights from the end of the best epoch: 3.\n",
      "183/183 [==============================] - 3s 14ms/step - loss: 0.2035 - accuracy: 0.8831 - val_loss: 0.5272 - val_accuracy: 0.7406\n",
      "Epoch 6: early stopping\n",
      "\n",
      "--- Hybrid 1D-CNN-LSTM Stage 1 Evaluation ---\n",
      "1586/1586 [==============================] - 8s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.88      0.28      2810\n",
      "           1       0.99      0.74      0.85     47940\n",
      "\n",
      "    accuracy                           0.75     50750\n",
      "   macro avg       0.58      0.81      0.56     50750\n",
      "weighted avg       0.94      0.75      0.81     50750\n",
      "\n",
      "\n",
      "--- Preparing Data for 1D-CNN-LSTM Stage 2 ---\n",
      "\n",
      "--- Training Hybrid 1D-CNN-LSTM Stage 2 (Classification) ---\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 8, 64)             7168      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 4, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 50)                23000     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 21)                1071      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,789\n",
      "Trainable params: 33,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "183/183 [==============================] - 6s 19ms/step - loss: 1.9051 - accuracy: 0.3928 - val_loss: 1.6785 - val_accuracy: 0.4276\n",
      "Epoch 2/20\n",
      "183/183 [==============================] - 3s 16ms/step - loss: 1.1982 - accuracy: 0.5951 - val_loss: 1.1867 - val_accuracy: 0.6743\n",
      "Epoch 3/20\n",
      "183/183 [==============================] - 3s 16ms/step - loss: 0.9105 - accuracy: 0.6943 - val_loss: 0.9887 - val_accuracy: 0.6758\n",
      "Epoch 4/20\n",
      "183/183 [==============================] - 3s 17ms/step - loss: 0.7397 - accuracy: 0.7472 - val_loss: 0.8197 - val_accuracy: 0.7024\n",
      "Epoch 5/20\n",
      "183/183 [==============================] - 3s 19ms/step - loss: 0.6438 - accuracy: 0.7717 - val_loss: 0.7656 - val_accuracy: 0.7059\n",
      "Epoch 6/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5793 - accuracy: 0.7910 - val_loss: 0.8517 - val_accuracy: 0.7005\n",
      "Epoch 7/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5427 - accuracy: 0.8021 - val_loss: 0.7719 - val_accuracy: 0.7098\n",
      "Epoch 8/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.5024 - accuracy: 0.8136 - val_loss: 0.7427 - val_accuracy: 0.7225\n",
      "Epoch 9/20\n",
      "183/183 [==============================] - 3s 18ms/step - loss: 0.4857 - accuracy: 0.8187 - val_loss: 0.8684 - val_accuracy: 0.6959\n",
      "Epoch 10/20\n",
      "183/183 [==============================] - 3s 17ms/step - loss: 0.4638 - accuracy: 0.8256 - val_loss: 0.8535 - val_accuracy: 0.6993\n",
      "Epoch 11/20\n",
      "181/183 [============================>.] - ETA: 0s - loss: 0.4501 - accuracy: 0.8308Restoring model weights from the end of the best epoch: 8.\n",
      "183/183 [==============================] - 2s 13ms/step - loss: 0.4493 - accuracy: 0.8311 - val_loss: 0.8334 - val_accuracy: 0.7183\n",
      "Epoch 11: early stopping\n",
      "\n",
      "--- Hybrid 1D-CNN-LSTM Stage 2 Evaluation ---\n",
      "1586/1586 [==============================] - 8s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.70      0.28      2810\n",
      "           1       0.95      0.83      0.89      2820\n",
      "           2       0.99      0.84      0.91      2820\n",
      "           4       0.98      0.84      0.90      2820\n",
      "           5       0.47      0.18      0.27      2820\n",
      "           6       1.00      0.44      0.61      2820\n",
      "           7       0.97      0.84      0.90      2820\n",
      "           8       0.59      0.71      0.64      2820\n",
      "          10       0.32      0.33      0.33      2820\n",
      "          11       0.91      0.80      0.85      2820\n",
      "          12       0.86      0.60      0.71      2820\n",
      "          13       0.59      0.70      0.64      2820\n",
      "          14       0.99      0.84      0.91      2820\n",
      "          16       0.20      0.04      0.07      2820\n",
      "          17       0.99      0.78      0.87      2820\n",
      "          18       0.85      0.33      0.48      2820\n",
      "          19       0.74      0.81      0.77      2820\n",
      "          20       0.51      0.75      0.60      2820\n",
      "\n",
      "    accuracy                           0.63     50750\n",
      "   macro avg       0.73      0.63      0.65     50750\n",
      "weighted avg       0.73      0.63      0.65     50750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Conv1D, Flatten, MaxPooling1D, Dropout, LSTM\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def create_lstm_dataset(X, y, time_steps=10):\n",
    "    \"\"\"Converts data into sequences for LSTM\"\"\"\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i:(i + time_steps)]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# --- 1. DATA PREPARATION (Load all data) ---\n",
    "print(\"Loading data...\")\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "# --- Prep for Stage 1 (Binary) ---\n",
    "train_data['binary_fault'] = train_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "test_data['binary_fault'] = test_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "y_train_s1 = train_data['binary_fault'].astype(int)\n",
    "y_test_s1 = test_data['binary_fault'].astype(int)\n",
    "\n",
    "# --- Prep for Stage 2 (Multiclass) ---\n",
    "y_train_s2_labels = train_data['faultNumber'].astype(int)\n",
    "y_test_s2_labels = test_data['faultNumber'].astype(int)\n",
    "\n",
    "all_labels = pd.concat([y_train_s2_labels, y_test_s2_labels])\n",
    "N_CLASSES = int(all_labels.max()) + 1\n",
    "print(f\"N_CLASSES set to {N_CLASSES}\")\n",
    "\n",
    "y_train_s2_cat = to_categorical(y_train_s2_labels, num_classes=N_CLASSES)\n",
    "y_test_s2_cat = to_categorical(y_test_s2_labels, num_classes=N_CLASSES)\n",
    "\n",
    "# --- Prep Features (X) ---\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample', 'binary_fault']\n",
    "X_train = train_data.drop(columns=drop_cols, errors='ignore')\n",
    "X_test = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "common_cols = sorted(list(set(X_train.columns).intersection(set(X_test.columns))))\n",
    "X_train = X_train[common_cols]\n",
    "X_test  = X_test[common_cols]\n",
    "\n",
    "print(f\"Data prepared with {len(common_cols)} common features.\")\n",
    "N_FEATURES = X_train.shape[1] # This will be 37\n",
    "\n",
    "# --- 2. SCALING (NO PADDING) ---\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# --- Define Model Parameters ---\n",
    "TIME_STEPS = 10\n",
    "# The input shape is (time_steps, features)\n",
    "HYBRID_INPUT_SHAPE = (TIME_STEPS, N_FEATURES) \n",
    "\n",
    "# Define Early Stopping\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss', patience=3, verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "#  STAGE 1: HYBRID 1D-CNN-LSTM (BINARY)\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n--- Preparing Data for 1D-CNN-LSTM Stage 1 ---\")\n",
    "# Create sequences from the UNPADDED data\n",
    "X_train_s1_seq, y_train_s1_seq = create_lstm_dataset(X_train_scaled, y_train_s1.values, TIME_STEPS)\n",
    "X_test_s1_seq, y_test_s1_seq = create_lstm_dataset(X_test_scaled, y_test_s1.values, TIME_STEPS)\n",
    "\n",
    "# Calculate class weights for Stage 1\n",
    "weights_s1 = class_weight.compute_class_weight(\n",
    "    'balanced', classes=np.unique(y_train_s1_seq), y=y_train_s1_seq\n",
    ")\n",
    "class_weights_dict_s1 = dict(zip(np.unique(y_train_s1_seq), weights_s1))\n",
    "\n",
    "def build_cnn1d_lstm_stage1(input_shape):\n",
    "    model = Sequential()\n",
    "    # 1. 1D-CNN Feature Extractor\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # 2. LSTM Sequence Learner\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    \n",
    "    # 3. Classifier Head\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"\\n--- Training Hybrid 1D-CNN-LSTM Stage 1 (Detection) ---\")\n",
    "model_s1_hybrid = build_cnn1d_lstm_stage1(HYBRID_INPUT_SHAPE)\n",
    "model_s1_hybrid.summary()\n",
    "\n",
    "model_s1_hybrid.fit(X_train_s1_seq, y_train_s1_seq,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    class_weight=class_weights_dict_s1,\n",
    "                    callbacks=[early_stopper])\n",
    "\n",
    "print(\"\\n--- Hybrid 1D-CNN-LSTM Stage 1 Evaluation ---\")\n",
    "y_pred_s1_hybrid = (model_s1_hybrid.predict(X_test_s1_seq) > 0.5).astype(\"int32\")\n",
    "print(classification_report(y_test_s1_seq, y_pred_s1_hybrid, zero_division=0))\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "#  STAGE 2: HYBRID 1D-CNN-LSTM (MULTICLASS)\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n--- Preparing Data for 1D-CNN-LSTM Stage 2 ---\")\n",
    "# Create sequences from UNPADDED data and CATEGORICAL labels\n",
    "X_train_s2_seq, y_train_s2_seq_cat = create_lstm_dataset(X_train_scaled, y_train_s2_cat, TIME_STEPS)\n",
    "\n",
    "# --- [FIXED LINE HERE] ---\n",
    "# Changed 'y_test_cat' to 'y_test_s2_cat'\n",
    "X_test_s2_seq, y_test_s2_seq_cat = create_lstm_dataset(X_test_scaled, y_test_s2_cat, TIME_STEPS)\n",
    "# --- [END OF FIX] ---\n",
    "\n",
    "# Create y labels for evaluation\n",
    "_, y_test_s2_seq_labels = create_lstm_dataset(X_test_scaled, y_test_s2_labels.values, TIME_STEPS)\n",
    "\n",
    "# Calculate class weights for Stage 2\n",
    "_, y_train_s2_seq_labels = create_lstm_dataset(X_train_scaled, y_train_s2_labels.values, TIME_STEPS)\n",
    "unique_labels_s2_seq = np.unique(y_train_s2_seq_labels)\n",
    "weights_s2 = class_weight.compute_class_weight(\n",
    "    'balanced', classes=unique_labels_s2_seq, y=y_train_s2_seq_labels\n",
    ")\n",
    "class_weights_dict_s2 = {i: 1.0 for i in range(N_CLASSES)}\n",
    "calculated_dict_s2 = dict(zip(unique_labels_s2_seq, weights_s2))\n",
    "class_weights_dict_s2.update(calculated_dict_s2)\n",
    "\n",
    "def build_cnn1d_lstm_stage2(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    # 1. 1D-CNN Feature Extractor\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "    # 2. LSTM Sequence Learner\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    \n",
    "    # 3. Classifier Head\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"\\n--- Training Hybrid 1D-CNN-LSTM Stage 2 (Classification) ---\")\n",
    "model_s2_hybrid = build_cnn1d_lstm_stage2(HYBRID_INPUT_SHAPE, N_CLASSES)\n",
    "model_s2_hybrid.summary()\n",
    "\n",
    "model_s2_hybrid.fit(X_train_s2_seq, y_train_s2_seq_cat,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    validation_split=0.1,\n",
    "                    class_weight=class_weights_dict_s2,\n",
    "                    callbacks=[early_stopper])\n",
    "\n",
    "print(\"\\n--- Hybrid 1D-CNN-LSTM Stage 2 Evaluation ---\")\n",
    "y_pred_s2_hybrid_probs = model_s2_hybrid.predict(X_test_s2_seq)\n",
    "y_pred_s2_hybrid_labels = np.argmax(y_pred_s2_hybrid_probs, axis=1)\n",
    "\n",
    "print(classification_report(y_test_s2_seq_labels, y_pred_s2_hybrid_labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd508112-2b10-486d-ad50-9d34b7cee8c0",
   "metadata": {},
   "source": [
    "Here we get the result that 1D CNN LSTM model is working better and rather best among all the models built so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783f693-853f-403c-857f-8abdeca406f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
